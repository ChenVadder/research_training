{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport logging\nimport datasets\n\nimport pandas as pd\nimport numpy as np\n\nfrom transformers import BertTokenizerFast, BertForSequenceClassification, DataCollatorWithPadding\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-13T09:29:47.732927Z","iopub.execute_input":"2023-01-13T09:29:47.733549Z","iopub.status.idle":"2023-01-13T09:29:57.003374Z","shell.execute_reply.started":"2023-01-13T09:29:47.733476Z","shell.execute_reply":"2023-01-13T09:29:57.002335Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/kumarmanoj-bag-of-words-meets-bags-of-popcorn/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\ntest = pd.read_csv(\"../input/kumarmanoj-bag-of-words-meets-bags-of-popcorn/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:57.005369Z","iopub.execute_input":"2023-01-13T09:29:57.006097Z","iopub.status.idle":"2023-01-13T09:29:58.449437Z","shell.execute_reply.started":"2023-01-13T09:29:57.006054Z","shell.execute_reply":"2023-01-13T09:29:58.448461Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"program = os.path.basename(sys.argv[0])\nlogger = logging.getLogger(program)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:58.450949Z","iopub.execute_input":"2023-01-13T09:29:58.451346Z","iopub.status.idle":"2023-01-13T09:29:58.457512Z","shell.execute_reply.started":"2023-01-13T09:29:58.451293Z","shell.execute_reply":"2023-01-13T09:29:58.456385Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\nlogging.root.setLevel(level=logging.INFO)\nlogger.info(r\"running %s\" % ''.join(sys.argv))","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:58.460471Z","iopub.execute_input":"2023-01-13T09:29:58.461475Z","iopub.status.idle":"2023-01-13T09:29:58.467547Z","shell.execute_reply.started":"2023-01-13T09:29:58.461440Z","shell.execute_reply":"2023-01-13T09:29:58.466520Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train, val = train_test_split(train, test_size=.2)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:58.468964Z","iopub.execute_input":"2023-01-13T09:29:58.469481Z","iopub.status.idle":"2023-01-13T09:29:58.487291Z","shell.execute_reply.started":"2023-01-13T09:29:58.469443Z","shell.execute_reply":"2023-01-13T09:29:58.486326Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_dict = {'label': train[\"sentiment\"], 'text': train['review']}\nval_dict = {'label': val[\"sentiment\"], 'text': val['review']}\ntest_dict = {\"text\": test['review']}","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:58.489491Z","iopub.execute_input":"2023-01-13T09:29:58.490180Z","iopub.status.idle":"2023-01-13T09:29:58.498679Z","shell.execute_reply.started":"2023-01-13T09:29:58.490144Z","shell.execute_reply":"2023-01-13T09:29:58.497705Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataset = datasets.Dataset.from_dict(train_dict)\nval_dataset = datasets.Dataset.from_dict(val_dict)\ntest_dataset = datasets.Dataset.from_dict(test_dict)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:58.500246Z","iopub.execute_input":"2023-01-13T09:29:58.500679Z","iopub.status.idle":"2023-01-13T09:29:58.706118Z","shell.execute_reply.started":"2023-01-13T09:29:58.500630Z","shell.execute_reply":"2023-01-13T09:29:58.705137Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:58.707829Z","iopub.execute_input":"2023-01-13T09:29:58.708242Z","iopub.status.idle":"2023-01-13T09:30:00.230119Z","shell.execute_reply.started":"2023-01-13T09:29:58.708206Z","shell.execute_reply":"2023-01-13T09:30:00.229090Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0311cb07f3234d0092137921eabb250b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af4ccd926a804017903d700f74ff428d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42992f203ffc40608a8b34aa9bc61a11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61f342909e984c28bb180d7ef95e5268"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples['text'], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:30:00.234792Z","iopub.execute_input":"2023-01-13T09:30:00.237267Z","iopub.status.idle":"2023-01-13T09:30:00.244606Z","shell.execute_reply.started":"2023-01-13T09:30:00.237215Z","shell.execute_reply":"2023-01-13T09:30:00.243555Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_val = val_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:30:00.249334Z","iopub.execute_input":"2023-01-13T09:30:00.252551Z","iopub.status.idle":"2023-01-13T09:30:41.627020Z","shell.execute_reply.started":"2023-01-13T09:30:00.252509Z","shell.execute_reply":"2023-01-13T09:30:41.626002Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dcf9fc1529f4dedab491b64b7157876"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb8e3d33c84d4f3daef219a11a792ef0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"181b9ba7f7794bdd80e5f6b7239c2586"}},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:30:41.628326Z","iopub.execute_input":"2023-01-13T09:30:41.628793Z","iopub.status.idle":"2023-01-13T09:30:41.633595Z","shell.execute_reply.started":"2023-01-13T09:30:41.628755Z","shell.execute_reply":"2023-01-13T09:30:41.632706Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:30:41.635006Z","iopub.execute_input":"2023-01-13T09:30:41.635657Z","iopub.status.idle":"2023-01-13T09:30:59.102586Z","shell.execute_reply.started":"2023-01-13T09:30:41.635616Z","shell.execute_reply":"2023-01-13T09:30:59.101585Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ac26cf743f848f5b0bf5c773fa0e9e4"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"metric = datasets.load_metric(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:30:59.104052Z","iopub.execute_input":"2023-01-13T09:30:59.104513Z","iopub.status.idle":"2023-01-13T09:30:59.465713Z","shell.execute_reply.started":"2023-01-13T09:30:59.104473Z","shell.execute_reply":"2023-01-13T09:30:59.464642Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"986a9ff511ed43e2bc6628f5bff90417"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:30:59.467274Z","iopub.execute_input":"2023-01-13T09:30:59.467639Z","iopub.status.idle":"2023-01-13T09:30:59.473257Z","shell.execute_reply.started":"2023-01-13T09:30:59.467602Z","shell.execute_reply":"2023-01-13T09:30:59.471603Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./checkpoint',  # output directory\n    num_train_epochs=3,  # total number of training epochs\n    per_device_train_batch_size=16,  # batch size per device during training\n    per_device_eval_batch_size=32,  # batch size for evaluation\n    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,  # strength of weight decay\n    logging_dir='./logs',  # directory for storing logs\n    logging_steps=100,\n    save_strategy=\"no\",\n    evaluation_strategy=\"epoch\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:30:59.474906Z","iopub.execute_input":"2023-01-13T09:30:59.475244Z","iopub.status.idle":"2023-01-13T09:30:59.575933Z","shell.execute_reply.started":"2023-01-13T09:30:59.475207Z","shell.execute_reply":"2023-01-13T09:30:59.574946Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,  # the instantiated 🤗 Transformers model to be trained\n    args=training_args,  # training arguments, defined above\n    train_dataset=tokenized_train,  # training dataset\n    eval_dataset=tokenized_val,  # evaluation dataset\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:30:59.577595Z","iopub.execute_input":"2023-01-13T09:30:59.578002Z","iopub.status.idle":"2023-01-13T09:31:04.808513Z","shell.execute_reply.started":"2023-01-13T09:30:59.577964Z","shell.execute_reply":"2023-01-13T09:31:04.807550Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:31:04.809815Z","iopub.execute_input":"2023-01-13T09:31:04.810171Z","iopub.status.idle":"2023-01-13T10:27:34.212339Z","shell.execute_reply.started":"2023-01-13T09:31:04.810137Z","shell.execute_reply":"2023-01-13T10:27:34.211419Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 20000\n  Num Epochs = 3\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 1\n  Total optimization steps = 3750\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.9 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230113_093124-12j8w4d2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/yn/huggingface/runs/12j8w4d2\" target=\"_blank\">./checkpoint</a></strong> to <a href=\"https://wandb.ai/yn/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3750/3750 56:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.246800</td>\n      <td>0.201501</td>\n      <td>0.920600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.122900</td>\n      <td>0.261434</td>\n      <td>0.934600</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.047100</td>\n      <td>0.286189</td>\n      <td>0.937600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 5000\n  Batch size = 32\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 5000\n  Batch size = 32\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 5000\n  Batch size = 32\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3750, training_loss=0.17986709213256835, metrics={'train_runtime': 3389.3465, 'train_samples_per_second': 17.703, 'train_steps_per_second': 1.106, 'total_flos': 1.564954957287552e+16, 'train_loss': 0.17986709213256835, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"prediction_outputs = trainer.predict(tokenized_test)\ntest_pred = np.argmax(prediction_outputs[0], axis=-1).flatten()\nprint(test_pred)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T10:27:34.214159Z","iopub.execute_input":"2023-01-13T10:27:34.216496Z","iopub.status.idle":"2023-01-13T10:34:24.933064Z","shell.execute_reply.started":"2023-01-13T10:27:34.216448Z","shell.execute_reply":"2023-01-13T10:34:24.932049Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Prediction *****\n  Num examples = 25000\n  Batch size = 32\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [782/782 06:50]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"[1 0 1 ... 0 1 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"result_output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\nresult_output.to_csv(\"/kaggle/working/bert_trainer.csv\", index=False, quoting=3)\nlogging.info('result saved!')\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T10:36:04.870112Z","iopub.execute_input":"2023-01-13T10:36:04.870886Z","iopub.status.idle":"2023-01-13T10:36:04.914614Z","shell.execute_reply.started":"2023-01-13T10:36:04.870839Z","shell.execute_reply":"2023-01-13T10:36:04.913559Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}